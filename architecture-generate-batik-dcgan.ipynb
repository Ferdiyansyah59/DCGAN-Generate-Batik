{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11339268,"sourceType":"datasetVersion","datasetId":7093858}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Conv2D, Conv2DTranspose, Layer, Reshape, BatchNormalization, Lambda, Add, Dropout, ReLU, LeakyReLU, Activation, Dropout, Flatten, GaussianNoise\nfrom tensorflow.keras.utils import image_dataset_from_directory\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras.initializers import HeNormal\n\n# Multi-GPU setup\n# strategy = tf.distribute.MirroredStrategy()\n# print(f\"🔧 Number of devices: {strategy.num_replicas_in_sync}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T18:02:14.415857Z","iopub.execute_input":"2025-04-10T18:02:14.416155Z","iopub.status.idle":"2025-04-10T18:02:14.420793Z","shell.execute_reply.started":"2025-04-10T18:02:14.416134Z","shell.execute_reply":"2025-04-10T18:02:14.419942Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T18:02:17.715718Z","iopub.execute_input":"2025-04-10T18:02:17.716043Z","iopub.status.idle":"2025-04-10T18:02:17.720521Z","shell.execute_reply.started":"2025-04-10T18:02:17.716016Z","shell.execute_reply":"2025-04-10T18:02:17.719858Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# gpus = tf.config.list_physical_devices('GPU')\n# print(f\"🖥️ Total GPU terdeteksi: {len(gpus)}\")\n# for i, gpu in enumerate(gpus):\n#     print(f\" - GPU {i}: {gpu}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T18:02:20.171849Z","iopub.execute_input":"2025-04-10T18:02:20.172195Z","iopub.status.idle":"2025-04-10T18:02:20.175413Z","shell.execute_reply.started":"2025-04-10T18:02:20.172165Z","shell.execute_reply":"2025-04-10T18:02:20.174635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMG_SIZE = (128, 128)\nBATCH = 32\nDIR = '/kaggle/input/dataset-batik-campuran'\nDEST_PATH = '/kaggle/working/batik_campuran'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T18:02:22.131265Z","iopub.execute_input":"2025-04-10T18:02:22.131606Z","iopub.status.idle":"2025-04-10T18:02:22.135324Z","shell.execute_reply.started":"2025-04-10T18:02:22.131574Z","shell.execute_reply":"2025-04-10T18:02:22.134617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\n\nshutil.copytree(DIR, DEST_PATH)\n\n# Step 2: Rename semua file di folder itu\nfor filename in os.listdir(DEST_PATH):\n    new_filename = (\n        filename.replace(\" \", \"_\")\n                .replace(\"(\", \"\")\n                .replace(\")\", \"\")\n                .replace(\"'\", \"\")\n    )\n    old_path = os.path.join(DEST_PATH, filename)\n    new_path = os.path.join(DEST_PATH, new_filename)\n\n    if old_path != new_path:\n        print(f\"Renaming: {filename} -> {new_filename}\")\n        os.rename(old_path, new_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T18:02:23.711090Z","iopub.execute_input":"2025-04-10T18:02:23.711425Z","iopub.status.idle":"2025-04-10T18:02:23.743690Z","shell.execute_reply.started":"2025-04-10T18:02:23.711398Z","shell.execute_reply":"2025-04-10T18:02:23.742690Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pathlib import Path\n\nfolder = Path(\"/kaggle/working/batik_campuran/batik_campuran\")\n\nfor file in folder.iterdir():\n    if file.is_file():\n        new_name = (\n            file.name.replace(\" \", \"_\")\n                     .replace(\"(\", \"\")\n                     .replace(\")\", \"\")\n        )\n        new_path = file.parent / new_name\n        if file.name != new_name:\n            print(f\"Renaming: {file.name} -> {new_name}\")\n            file.rename(new_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T17:50:10.692904Z","iopub.execute_input":"2025-04-10T17:50:10.693256Z","iopub.status.idle":"2025-04-10T17:50:10.720432Z","shell.execute_reply.started":"2025-04-10T17:50:10.693228Z","shell.execute_reply":"2025-04-10T17:50:10.719742Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport imghdr\nfrom PIL import Image\nimport shutil\n\nSRC = \"/kaggle/working/batik_campuran/batik_campuran\"\nDST = \"/kaggle/working/batik_campuran_valid\"\nos.makedirs(DST, exist_ok=True)\n\nfor filename in os.listdir(SRC):\n    src_path = os.path.join(SRC, filename)\n    dst_path = os.path.join(DST, filename)\n\n    if os.path.isfile(src_path):\n        try:\n            # pastikan benar-benar file image\n            img_type = imghdr.what(src_path)\n            if img_type in [\"jpeg\", \"png\", \"bmp\", \"gif\"]:\n                with Image.open(src_path) as img:\n                    img.verify()\n                shutil.copy2(src_path, dst_path)\n            else:\n                print(f\"Skipping (not image): {filename} — Detected as {img_type}\")\n        except Exception as e:\n            print(f\"Skipping (error): {filename} — {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T17:50:14.559209Z","iopub.execute_input":"2025-04-10T17:50:14.559520Z","iopub.status.idle":"2025-04-10T17:50:14.957713Z","shell.execute_reply.started":"2025-04-10T17:50:14.559482Z","shell.execute_reply":"2025-04-10T17:50:14.957073Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img\nimport random\n\n# Path ke folder gambar asli\nfolder_path = DST\n\n# Augmentasi ringan\ndef random_augment(image):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_brightness(image, max_delta=0.1)\n    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n    \n    # Rotate 0, 90, 180, atau 270 derajat\n    k = random.choice([0, 1, 2, 3])\n    image = tf.image.rot90(image, k=k)\n    \n    return image\n\n# Loop semua file di folder\nfor filename in os.listdir(folder_path):\n    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n        image_path = os.path.join(folder_path, filename)\n        image = load_img(image_path)\n        image = img_to_array(image)\n\n        # Resize kalau perlu (misalnya resize ke 128x128)\n        image = tf.image.resize(image, [128, 128])\n        image = tf.cast(image, tf.uint8)\n\n        # Augment 3x per gambar\n        for i in range(3):\n            aug_img = random_augment(image)\n            aug_img = tf.clip_by_value(aug_img, 0, 255)\n            aug_img = array_to_img(aug_img)\n\n            new_filename = filename.split('.')[0] + f'_aug{i}.jpg'\n            aug_img.save(os.path.join(folder_path, new_filename))\n\nprint(\"Augmentasi selesai 🚀\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T17:51:01.341052Z","iopub.execute_input":"2025-04-10T17:51:01.341372Z","iopub.status.idle":"2025-04-10T17:52:05.222564Z","shell.execute_reply.started":"2025-04-10T17:51:01.341349Z","shell.execute_reply":"2025-04-10T17:52:05.221610Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = image_dataset_from_directory (\n    \"/kaggle/working/batik_campuran_valid\",\n    batch_size=BATCH,\n    image_size=IMG_SIZE,\n    class_names=None,\n    label_mode=None\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T18:02:32.344764Z","iopub.execute_input":"2025-04-10T18:02:32.345063Z","iopub.status.idle":"2025-04-10T18:02:32.581081Z","shell.execute_reply.started":"2025-04-10T18:02:32.345040Z","shell.execute_reply":"2025-04-10T18:02:32.580439Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess(image):\n    img = tf.image.resize(image, [128, 128], method='bicubic')\n    img = tf.cast(img, tf.float32) / 127.5 - 1.0\n    return img\n\ndataset = dataset.map(preprocess).shuffle(500).prefetch(buffer_size=tf.data.AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T18:02:35.010779Z","iopub.execute_input":"2025-04-10T18:02:35.011084Z","iopub.status.idle":"2025-04-10T18:02:35.028878Z","shell.execute_reply.started":"2025-04-10T18:02:35.011060Z","shell.execute_reply":"2025-04-10T18:02:35.028008Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def color_augment(x):\n#     x = tf.image.random_brightness(x, max_delta=0.1)\n#     x = tf.image.random_saturation(x, lower=0.8, upper=1.2)\n#     return tf.clip_by_value(x, 0.0, 1.0)\n\n# def translation_augment(x):\n#     img_shape = tf.shape(x)\n#     shift_x = \n\n\n# def diff_augment(x, policy='color, translation'):\n#     if 'color' in policy:\n#         x = color_augmentx = tf.image.random_brightness(x, max_delta=0.1)\n#     x = tf.image.random_saturation(x, lower=0.8, upper=1.2)\n#     return tf.clip_by_value(x, 0.0, 1.0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T17:52:12.144522Z","iopub.execute_input":"2025-04-10T17:52:12.144869Z","iopub.status.idle":"2025-04-10T17:52:12.148496Z","shell.execute_reply.started":"2025-04-10T17:52:12.144840Z","shell.execute_reply":"2025-04-10T17:52:12.147635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def translation_augment(x, ratio=0.02):\n    shape = tf.shape(x)\n    shift_x = tf.cast(ratio * tf.cast(shape[1], tf.float32), tf.int32)\n    shift_y = tf.cast(ratio * tf.cast(shape[2], tf.float32), tf.int32)\n\n    dx = tf.random.uniform([], -shift_x, shift_x + 1, dtype=tf.int32)\n    dy = tf.random.uniform([], -shift_y, shift_y + 1, dtype=tf.int32)\n\n    return tf.roll(x, shift=[dx, dy], axis=[1, 2])\n\n\ndef diff_augment(x, policy='translation'):\n    if 'translation' in policy:\n        x = translation_augment(x)\n    return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T18:02:37.793890Z","iopub.execute_input":"2025-04-10T18:02:37.794251Z","iopub.status.idle":"2025-04-10T18:02:37.802714Z","shell.execute_reply.started":"2025-04-10T18:02:37.794223Z","shell.execute_reply":"2025-04-10T18:02:37.801735Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ambil satu batch dari dataset\nfor batch in dataset.take(1):\n    batch_image = batch.numpy()  # kalau label ikut, bisa unpack: batch_image, _ = batch\n    break\n\n# Rescale dari [-1, 1] ke [0, 255]\nbatch_image = ((batch_image + 1) * 127.5).astype(np.uint8)\n\n# Plot gambar\nplt.figure(figsize=(10, 10))\nfor i in range(min(5, len(batch_image))):\n    plt.subplot(1, 5, i + 1)\n    plt.imshow(batch_image[i])\n    plt.axis('off')\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T17:53:26.409823Z","iopub.execute_input":"2025-04-10T17:53:26.410140Z","iopub.status.idle":"2025-04-10T17:53:30.053274Z","shell.execute_reply.started":"2025-04-10T17:53:26.410114Z","shell.execute_reply":"2025-04-10T17:53:30.052182Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !ls /kaggle/working/batik_campuran/batik_campuran -R\n\n# import os\n\n# dst_folder = \"/kaggle/working/batik_campuran/batik_campuran\"\n\n# for filename in os.listdir(dst_folder):\n#     print(repr(filename))\n\n# print(sorted(os.listdir(\"/kaggle/working/batik_campuran/batik_campuran\")))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T17:53:34.945308Z","iopub.execute_input":"2025-04-10T17:53:34.945593Z","iopub.status.idle":"2025-04-10T17:53:34.949573Z","shell.execute_reply.started":"2025-04-10T17:53:34.945570Z","shell.execute_reply":"2025-04-10T17:53:34.948648Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# KI = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n# input_dim = 128\n\n# def build_generator():\n#     Generator = Sequential()\n\n#     Generator.add(Dense(8 * 8 * 512, input_dim = input_dim))\n#     Generator.add(ReLU())\n    \n#     Generator.add(Reshape((8, 8, 512)))\n\n#     # karena input mulai dari 8 berati ini 16x16x256 karena stridesnya 2 jadi nanti dibikin 2x lipat 256->128\n#     Generator.add(Conv2DTranspose(256, kernel_size=4, strides=2, padding='same'))\n#     Generator.add(BatchNormalization())\n#     Generator.add(ReLU())\n\n#     # Nah ini udah 32x32x128\n#     Generator.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding='same'))\n#     Generator.add(BatchNormalization())\n#     Generator.add(ReLU())\n\n#     # Sekarang 64x64x64\n#     Generator.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding='same'))\n#     Generator.add(BatchNormalization())\n#     Generator.add(ReLU())\n\n#     # Sekarang 128x128x32\n#     Generator.add(Conv2DTranspose(32, kernel_size=4, strides=2, padding='same'))\n#     Generator.add(BatchNormalization())\n#     Generator.add(ReLU())\n\n#     # Sekarang 256x256x3. Nah disini udh sampe ke 256 berarti udah sama kayak image_size nya. \n#     # Disini kenapa 32 langsung lonncat 3 itu gpp karena disini 3 merejuk ke channel gambar RGB\n#     # Disini output layers, tetep pake Tranpose karena generator itu buat bikin gambar jadi butuh upsampling bukan down\n#     Generator.add(Conv2DTranpose(3, kernel_size=4, strides=2, padding='same'))\n#     Generator.add(Activation('tanh'))\n\n#     return Generator\n\n# generator = build_generator()\n# generator.summary()\n\n# keras.utils.plot_model(generator, show_shapes=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T17:53:35.217441Z","iopub.execute_input":"2025-04-10T17:53:35.217727Z","iopub.status.idle":"2025-04-10T17:53:35.221462Z","shell.execute_reply.started":"2025-04-10T17:53:35.217703Z","shell.execute_reply":"2025-04-10T17:53:35.220512Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nKI = HeNormal()\n\nclass ResidualBlock(Layer):\n    def __init__(self, filters, **kwargs):\n        super(ResidualBlock, self).__init__(**kwargs)\n        self.conv1 = Conv2D(filters, kernel_size=3, strides=1, padding='same', kernel_initializer=KI)\n        self.bn1 = BatchNormalization()\n        self.relu1 = ReLU()\n        self.conv2 = Conv2D(filters, kernel_size=3, strides=1, padding='same', kernel_initializer=KI)\n        self.bn2 = BatchNormalization()\n        self.add = Add()\n        self.relu2 = ReLU()\n\n    def call(self, x):\n        skip = x\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu1(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.add([x, skip])\n        x = self.relu2(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T18:02:41.983852Z","iopub.execute_input":"2025-04-10T18:02:41.984140Z","iopub.status.idle":"2025-04-10T18:02:41.989735Z","shell.execute_reply.started":"2025-04-10T18:02:41.984116Z","shell.execute_reply":"2025-04-10T18:02:41.989083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"KI = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\ninput_dim = 256\n\ndef build_generator():\n    Generator = Sequential()\n\n    Generator.add(Dense(4 * 4 * 1024, input_dim = input_dim))\n    Generator.add(LeakyReLU(alpha=0.2))\n    \n    Generator.add(Reshape((4, 4, 1024)))\n    Generator.add(GaussianNoise(0.1))\n\n    # karena input mulai dari 4 berati ini 8x8x512 karena stridesnya 2 jadi nanti dibikin 2x lipat 256->128\n    Generator.add(Conv2DTranspose(512, kernel_size=4, strides=2, padding='same', kernel_initializer=KI))\n    Generator.add(BatchNormalization())\n    Generator.add(LeakyReLU(alpha=0.2))\n\n    # Nah ini udah 16x16x256\n    Generator.add(Conv2DTranspose(256, kernel_size=4, strides=2, padding='same', kernel_initializer=KI))\n    Generator.add(BatchNormalization())\n    Generator.add(LeakyReLU(alpha=0.2))\n\n    # Sekarang 32x32x128\n    Generator.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', kernel_initializer=KI))\n    Generator.add(BatchNormalization())\n    Generator.add(LeakyReLU(alpha=0.2))\n\n    Generator.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', kernel_initializer=KI))\n    Generator.add(BatchNormalization())\n    Generator.add(LeakyReLU(alpha=0.2))\n\n    Generator.add(Conv2DTranspose(64, kernel_size=4, strides=1, padding='same', kernel_initializer=KI))\n    Generator.add(BatchNormalization())\n    Generator.add(LeakyReLU(alpha=0.2))\n\n    Generator.add(ResidualBlock(64))\n    Generator.add(ResidualBlock(64))\n\n    # Sekarang 256x256x3. Nah disini udh sampe ke 256 berarti udah sama kayak image_size nya. \n    # Disini kenapa 32 langsung lonncat 3 itu gpp karena disini 3 merejuk ke channel gambar RGB\n    # Disini output layers, tetep pake Tranpose karena generator itu buat bikin gambar jadi butuh upsampling bukan downsampling\n    Generator.add(Conv2DTranspose(3, kernel_size=4, strides=2, padding='same', kernel_initializer=KI))\n    Generator.add(Activation('tanh'))\n\n    return Generator\n\ngenerator = build_generator()\ngenerator.summary()\n\nkeras.utils.plot_model(generator, show_shapes=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T18:02:47.322077Z","iopub.execute_input":"2025-04-10T18:02:47.322364Z","iopub.status.idle":"2025-04-10T18:02:48.570187Z","shell.execute_reply.started":"2025-04-10T18:02:47.322343Z","shell.execute_reply":"2025-04-10T18:02:48.569244Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_discriminator():\n    input_shape = (128, 128, 3)\n\n    Discriminator = Sequential()\n    \n    Discriminator.add(Conv2D(32, kernel_size=4, strides=2, padding='same', input_shape=input_shape))\n    Discriminator.add(LeakyReLU(alpha=0.2))\n    Discriminator.add(Dropout(0.2))\n    \n\n    Discriminator.add(Conv2D(64, kernel_size=4, strides=2, padding='same'))\n    Discriminator.add(LeakyReLU(alpha=0.2))\n    Discriminator.add(Dropout(0.2))\n    \n\n    Discriminator.add(Conv2D(128, kernel_size=4, strides=2, padding='same'))\n    Discriminator.add(LeakyReLU(alpha=0.2))\n    Discriminator.add(Dropout(0.2))\n    \n\n\n    Discriminator.add(Flatten())\n    \n    Discriminator.add(Dense(128))\n    Discriminator.add(LeakyReLU())\n    Discriminator.add(Dense(1, activation='sigmoid'))\n\n    return Discriminator\n\ndiscriminator = build_discriminator()\ndiscriminator.summary()\nkeras.utils.plot_model(discriminator, show_shapes=True, show_dtype=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T18:02:50.546515Z","iopub.execute_input":"2025-04-10T18:02:50.546890Z","iopub.status.idle":"2025-04-10T18:02:51.132716Z","shell.execute_reply.started":"2025-04-10T18:02:50.546853Z","shell.execute_reply":"2025-04-10T18:02:51.131740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport zipfile\n\nSAVE_DIR = \"/kaggle/working/GAN_Batik\"\nMODEL_DIR = os.path.join(SAVE_DIR, \"models\")\nIMG_DIR = os.path.join(SAVE_DIR, \"images\")\n\nos.makedirs(MODEL_DIR, exist_ok=True)\nos.makedirs(IMG_DIR, exist_ok=True)\n\n# Fungsi buat save gambar\ndef save_generated_images(generator, latent_dim, epoch, save_dir=IMG_DIR, n=5):\n    noise = tf.random.normal([n * n, latent_dim])\n    generated = generator(noise, training=False)\n    generated = (generated + 1) / 2.0  # scale ke [0, 1]\n\n    fig, axes = plt.subplots(n, n, figsize=(n, n))\n    idx = 0\n    for i in range(n):\n        for j in range(n):\n            axes[i][j].imshow(generated[idx])\n            axes[i][j].axis(\"off\")\n            idx += 1\n    plt.tight_layout()\n    filepath = os.path.join(save_dir, f\"epoch_{epoch+1}.png\")\n    plt.savefig(filepath)\n    plt.close()\n\n# Fungsi buat save model\ndef save_models(generator, discriminator, epoch, save_dir=MODEL_DIR):\n    gen_base = os.path.join(save_dir, f\"generator_epoch_{epoch+1}\")\n    disc_base = os.path.join(save_dir, f\"discriminator_epoch_{epoch+1}\")\n\n    # Simpan dalam format .keras (format baru, lebih aman buat custom layer)\n    generator.save(gen_base + \".keras\")\n    discriminator.save(disc_base + \".keras\")\n\n    # Simpan dalam format .h5 (lebih umum, tapi hati-hati kalo ada Lambda/custom layer)\n    generator.save(gen_base + \".h5\")\n    discriminator.save(disc_base + \".h5\")\n\n    # Simpan hanya weight-nya (.weights.h5)\n    generator.save_weights(gen_base + \".weights.h5\")\n    discriminator.save_weights(disc_base + \".weights.h5\")\n\n# Fungsi auto-zip setelah training selesai\ndef zip_output(zip_path=\"/kaggle/working/GAN_Batik.zip\", folder_to_zip=SAVE_DIR):\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, _, files in os.walk(folder_to_zip):\n            for file in files:\n                filepath = os.path.join(root, file)\n                arcname = os.path.relpath(filepath, folder_to_zip)\n                zipf.write(filepath, arcname)\n\n\ndef load_models(epoch, model_dir=MODEL_DIR):\n    gen_path = os.path.join(model_dir, f\"generator_epoch_{epoch}.keras\")\n    disc_path = os.path.join(model_dir, f\"discriminator_epoch_{epoch}.keras\")\n\n    generator = tf.keras.models.load_model(gen_path, compile=False)\n    discriminator = tf.keras.models.load_model(disc_path, compile=False)\n    return generator, discriminator\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T18:02:53.687906Z","iopub.execute_input":"2025-04-10T18:02:53.688205Z","iopub.status.idle":"2025-04-10T18:02:53.698183Z","shell.execute_reply.started":"2025-04-10T18:02:53.688183Z","shell.execute_reply":"2025-04-10T18:02:53.697233Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_and_plot_images(generator, latent_dim, n=5):\n    noise = tf.random.normal([n * n, latent_dim])\n    generated = generator(noise, training=False)\n    generated = generated.numpy()\n\n    fig, axes = plt.subplots(n, n, figsize=(n, n))\n    for i in range(n):\n        for j in range(n):\n            axes[i][j].imshow(generated[i * n + j])\n            axes[i][j].axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\ndef train_gan(generator, discriminator, dataset, latent_dim, g_optimizer, d_optimizer, loss_fn, epochs):\n    max_steps_per_epoch = 243  # Boleh disesuaikan\n\n    for epoch in range(epochs):\n        print(f\"\\n🌟 Epoch {epoch+1}/{epochs} mulai...\")\n        total_steps = min(len(dataset), max_steps_per_epoch)\n\n        for step, real_images in enumerate(dataset):\n            if step >= max_steps_per_epoch:\n                break\n                \n            real_images = tf.convert_to_tensor(real_images)\n            batch_size = real_images.shape[0]\n            random_noise = tf.random.normal(shape=(batch_size, latent_dim))\n\n            # ----------- Discriminator Training -----------\n            with tf.GradientTape() as tape:\n                # Tambah sedikit noise ke gambar real & fake (stabilin training)\n                real_images_noisy = real_images + tf.random.normal(tf.shape(real_images), mean=0.0, stddev=0.05)\n                fake_images = generator(random_noise, training=True)\n                fake_images_noisy = fake_images + tf.random.normal(tf.shape(fake_images), mean=0.0, stddev=0.05)\n\n                aug_real = diff_augment(real_images_noisy)\n                aug_fake = diff_augment(fake_images_noisy)\n                \n                pred_real = discriminator(aug_real, training=True)\n                pred_fake = discriminator(aug_fake, training=True)\n\n                real_labels = tf.ones_like(pred_real) * 0.9  # Label smoothing\n                fake_labels = tf.zeros_like(pred_fake)\n\n                d_loss_real = loss_fn(real_labels, pred_real)\n                d_loss_fake = loss_fn(fake_labels, pred_fake)\n                d_loss = (d_loss_real + d_loss_fake) / 2\n\n            gradients_d = tape.gradient(d_loss, discriminator.trainable_variables)\n            d_optimizer.apply_gradients(zip(gradients_d, discriminator.trainable_variables))\n\n            # ----------- Generator Training -----------\n            with tf.GradientTape() as tape:\n                fake_images = generator(random_noise, training=True)\n                pred_fake = discriminator(fake_images, training=True)\n                g_loss = loss_fn(tf.ones_like(pred_fake), pred_fake)\n\n            gradients_g = tape.gradient(g_loss, generator.trainable_variables)\n            g_optimizer.apply_gradients(zip(gradients_g, generator.trainable_variables))\n\n            # ----------- Tambahan step untuk Generator (opsional tuning) -----------\n            if d_loss < 0.3 and g_loss > 2.0:\n                for _ in range(2):  # Bisa kamu ubah jadi 1 atau 3, sesuai respon model\n                    noise_extra = tf.random.normal(shape=(batch_size, latent_dim))\n                    with tf.GradientTape() as tape:\n                        fake_images = generator(noise_extra, training=True)\n                        pred_fake = discriminator(fake_images, training=True)\n                        g_loss = loss_fn(tf.ones_like(pred_fake), pred_fake)\n                    gradients_g = tape.gradient(g_loss, generator.trainable_variables)\n                    g_optimizer.apply_gradients(zip(gradients_g, generator.trainable_variables))\n\n            # Logging per 50 step\n            if step % 50 == 0:\n                print(f\"🔁 Step {step}: D Loss = {d_loss.numpy():.4f}, G Loss = {g_loss.numpy():.4f}\")\n\n        print(f\"✅ Epoch {epoch+1} selesai: D Loss = {d_loss.numpy():.4f}, G Loss = {g_loss.numpy():.4f}\")\n\n        # Optional visualisasi hasil Generator per epoch\n        generate_and_plot_images(generator, latent_dim)\n\n        if (epoch + 1) % 10 == 0:\n            save_generated_images(generator, latent_dim, epoch)\n            save_models(generator, discriminator, epoch)\n\n        with open(os.path.join(SAVE_DIR, 'last_epoch.txt'), 'w') as f:\n            f.write(str(epoch + 1))\n\n            zip_output()\n\n\n\n    print(\"\\n🎉 Training selesai!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T18:02:56.687732Z","iopub.execute_input":"2025-04-10T18:02:56.688066Z","iopub.status.idle":"2025-04-10T18:02:56.700851Z","shell.execute_reply.started":"2025-04-10T18:02:56.688038Z","shell.execute_reply":"2025-04-10T18:02:56.699959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"latent_dim = 256\ng_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.5)\nd_optimizer = tf.keras.optimizers.Adam(learning_rate=4e-4, beta_1=0.5)\nloss_fn = tf.keras.losses.BinaryCrossentropy()\nprint(f\"Total batch per epoch (expected): {len(dataset)}\")  # Jumlah batch per epoch\n\n\n\ntrain_gan(generator, discriminator, dataset, latent_dim, g_optimizer, d_optimizer, loss_fn, epochs=300)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T18:02:59.926454Z","iopub.execute_input":"2025-04-10T18:02:59.926820Z","iopub.status.idle":"2025-04-11T03:16:13.890531Z","shell.execute_reply.started":"2025-04-10T18:02:59.926791Z","shell.execute_reply":"2025-04-11T03:16:13.889303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}